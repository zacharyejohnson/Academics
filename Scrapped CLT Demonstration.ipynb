{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datlib import distributions\n",
    "import scipy.stats as st\n",
    "\n",
    "fig, axs = plt.subplots(4, 10, figsize = (20, 10))\n",
    "\n",
    "for n in range(0, 100, 10):\n",
    "    x_spot = int((n / 10) - 1)\n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    axs[0, 0].plot(st.norm.pdf(x))\n",
    "    means_list = []\n",
    "    for x in range(n):\n",
    "        mean = np.random.normal(0, 1, size=n).mean()\n",
    "        means_list.append(mean)\n",
    "\n",
    "    axs[0, x_spot+1].set_title(\"n = \" + str(n), fontsize=20)\n",
    "    axs[0, x_spot+1].hist(means_list, bins=int(n/5) +1)\n",
    "\n",
    "for n in range(0, 100, 10):\n",
    "    x_spot = int((n / 10) - 1)\n",
    "    x = np.linspace(-5, 5, 1000)\n",
    "    axs[1, 0].plot(st.lognorm(0, 1).pdf(x))    \n",
    "    means_list = []\n",
    "    for x in range(n):\n",
    "        mean = np.random.lognormal(0, 1, size=n).mean()\n",
    "        means_list.append(mean)\n",
    "   \n",
    "    axs[1, x_spot+1].hist(means_list, bins=int(n/5) +1)\n",
    "\n",
    "for n in range(0, 100, 10):\n",
    "    x_spot = int((n / 10) - 1)\n",
    "    mu=.6\n",
    "    x = np.arange(st.poisson.ppf(0.01, mu),\n",
    "              st.poisson.ppf(0.99, mu))\n",
    "    axs[2, 0].plot(x, st.poisson.pmf(x, mu), 'bo', ms=8, label='poisson pmf')\n",
    "    means_list = []\n",
    "    for x in range(n):\n",
    "        mean = np.random.poisson(0.5, size=n).mean()\n",
    "        means_list.append(mean)\n",
    "\n",
    "    axs[2, x_spot+1].hist(means_list, bins=int(n/5) +1)\n",
    "\n",
    "for n in range(0, 100, 10):\n",
    "    x_spot = int((n / 10) - 1)\n",
    "    means_list = []\n",
    "    for x in range(n):\n",
    "        mean = np.random.binomial(n=n, p=0.5, size=n).mean()\n",
    "        means_list.append(mean)\n",
    "\n",
    "\n",
    "    axs[3, x_spot+1].hist(means_list, bins=int(n/5) +1)\n",
    "\n",
    "for n in range(0, 100, 10):\n",
    "    x_spot = int((n / 10)-1)\n",
    "    means_list = []\n",
    "    for x in range(n):\n",
    "        mean = np.random.exponential(1, size=n).mean()\n",
    "        means_list.append(mean)\n",
    "\n",
    "\n",
    "    axs[4, x_spot+1].hist(means_list, bins=int(n/5) +1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c62036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_samples_ttest(a, b, hypothesized_difference = 0):\n",
    "    if len(a) != len(b): \n",
    "        return \"Arguments must be of equal length\"\n",
    "    else:\n",
    "        differences_list = []\n",
    "        for i in range(len(a)): \n",
    "            differences_list.append(a[i] - b[i])\n",
    "        n = len(differences_list)\n",
    "        d = mean(differences_list)\n",
    "        sd = variance(differences_list)\n",
    "        t = (d - hypothesized_difference) / (sd / np.sqrt(n))\n",
    "        df = n-1\n",
    "        p_value = t_prob(t, df)\n",
    "        if p_value > .05:\n",
    "            return_string = \"T-value: \" + str(t) + \", P-value: \" + str(\n",
    "                p_value) + \", Fail to reject null hypothesis.\"\n",
    "        else:\n",
    "            return_string = \"T-value: \" + str(t) + \", P-value: \" + str(\n",
    "                round(p_value, 5)) + \", Reject null hypothesis.\"\n",
    "\n",
    "        return return_string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
